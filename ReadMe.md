# Emotion Detection API

## ğŸ“‹ Description du Projet

API d'analyse Ã©motionnelle basÃ©e sur l'IA qui dÃ©tecte automatiquement les visages dans des images et prÃ©dit les Ã©motions correspondantes. Ce projet a Ã©tÃ© dÃ©veloppÃ© comme prototype pour valider la faisabilitÃ© d'un futur produit SaaS destinÃ© aux tests produits et aux expÃ©riences UX.

## ğŸ¯ FonctionnalitÃ©s

- **DÃ©tection automatique de visages** : Utilisation d'OpenCV avec Haar Cascade
- **PrÃ©diction d'Ã©motions** : ModÃ¨le CNN entraÃ®nÃ© sur plusieurs Ã©motions (happy, sad, angry, surprised, etc.)
- **API REST** : Endpoints FastAPI pour la prÃ©diction et l'historique
- **Persistance des donnÃ©es** : Stockage des prÃ©dictions dans PostgreSQL
- **Tests automatisÃ©s** : Tests unitaires avec intÃ©gration CI/CD via GitHub Actions

## ğŸ› ï¸ Technologies UtilisÃ©es

- **Deep Learning** : TensorFlow/Keras
- **Computer Vision** : OpenCV
- **API Framework** : FastAPI
- **Base de donnÃ©es** : PostgreSQL
- **ORM** : SQLAlchemy
- **Tests** : pytest
- **CI/CD** : GitHub Actions

## ğŸ“¦ Installation

### PrÃ©requis

- Python 3.8+
- PostgreSQL
- pip

### Configuration de l'environnement

1. **Cloner le repository**
```bash
git clone https://github.com/Khaoula1025/Facial_Emotion_Detection.git
cd emotion-detection-api
```

2. **CrÃ©er un environnement virtuel**
```bash
python -m venv venv
source venv\Scripts\activate
```

3. **Installer les dÃ©pendances**
```bash
pip install -r requirements.txt
```

4. **Configurer la base de donnÃ©es PostgreSQL**
```bash
# CrÃ©er la base de donnÃ©es
createdb emotion_detection

# Configurer les variables d'environnement
cp .env.example .env
# Ã‰diter .env avec vos identifiants PostgreSQL
```

5. **TÃ©lÃ©charger le fichier Haar Cascade**
```bash
wget https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml
```

## ğŸš€ Utilisation

### 1. EntraÃ®nement du modÃ¨le CNN

```bash
# ExÃ©cuter le notebook Jupyter
jupyter notebook ml/notebooks/train_cnn_model.ipynb
```

Le notebook effectue :
- Chargement et prÃ©traitement des donnÃ©es
- Augmentation des images
- EntraÃ®nement du modÃ¨le CNN
- Sauvegarde du modÃ¨le (`.h5` ou `.keras`)
- Visualisation des mÃ©triques

### 2. Test de dÃ©tection et prÃ©diction standalone

```bash
python detect_and_predict.py 
```

### 3. Lancement de l'API

```bash
uvicorn main:app --reload 
```

L'API sera accessible Ã  : `http://localhost:8000`

Documentation interactive : `http://localhost:8000/docs`

## ğŸ“¡ Endpoints API

### POST `/predict_emotion`

PrÃ©dit l'Ã©motion d'un visage dans une image.

**Request:**
```bash
curl -X POST "http://localhost:8000/predict_emotion" 
```

**Response:**
```json
{
  "emotion": "happy",
  "confidence": 0.92,
  "id": 1,
  "created_at": "2025-11-14T10:30:00"
}
```

### GET `/history`

RÃ©cupÃ¨re l'historique des prÃ©dictions.

**Request:**
```bash
curl -X GET "http://localhost:8000/history"
```

**Response:**
```json
[
  {
    "id": 1,
    "emotion": "happy",
    "confidence": 0.92,
    "created_at": "2025-11-14T10:30:00"
  },
  {
    "id": 2,
    "emotion": "sad",
    "confidence": 0.87,
    "created_at": "2025-11-14T10:35:00"
  }
]
```

## ğŸ—‚ï¸ Structure du Projet

```
Facial_emotion-detection/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ db/
|   |    â”œâ”€â”€ database.py
|   |    â””â”€â”€ models.py
|   |
|   â”œâ”€â”€schemas/
|   |      â””â”€â”€ prediction.py
|   â”œâ”€â”€utils/
|   |      â””â”€â”€ predictionScript.py
|   â””â”€â”€ main.py
â”‚
â”œâ”€â”€ ml/
â”‚   â”œâ”€â”€images
|   â”œâ”€â”€ml_models/
|   |     â”œâ”€â”€ emotion_detection.keras
|   |     â””â”€â”€ haarcascade_frontface_default.xml
|   â”œâ”€â”€notebooks/
|   |       â””â”€â”€ train_cnn_model.ipynb
|   â””â”€â”€ detect_and_predict.py 
|       
â”œâ”€â”€ data/
â”‚   â””â”€â”€ test/
|   â””â”€â”€ train/ 
â”‚
â”œâ”€â”€ test_ml.py             
â”œâ”€â”€ test_api.py               
â”‚
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚          â””â”€â”€ python_test.yml              
|
â”œâ”€â”€ requirements.txt              
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## ğŸ§ª Tests

### ExÃ©cuter les tests unitaires

```bash
pytest tests/ -v
```

### Tests couverts

- âœ… Sauvegarde et rechargement du modÃ¨le
- âœ… Format des prÃ©dictions
- âœ… Endpoints API
- âœ… DÃ©tection de visages
- âœ… Connexion Ã  la base de donnÃ©es

### Tests automatisÃ©s (CI/CD)

Les tests sont automatiquement exÃ©cutÃ©s via GitHub Actions Ã  chaque push/PR.

## ğŸ—„ï¸ SchÃ©ma de Base de DonnÃ©es

**Table: predictions**

| Colonne      | Type      | Description                    |
|--------------|-----------|--------------------------------|
| id           | SERIAL    | ClÃ© primaire auto-incrÃ©mentÃ©e  |
| emotion      | VARCHAR   | Ã‰motion prÃ©dite                |
| confidence   | FLOAT     | Score de confiance (0-1)       |
| created_at   | TIMESTAMP | Date et heure de la prÃ©diction |

## ğŸ“Š ModÃ¨le CNN

### Architecture

```
Input (48x48x1 ou 48x48x3)
    â†“
Conv2D(32) + ReLU + MaxPooling
    â†“
Conv2D(64) + ReLU + MaxPooling
    â†“
Conv2D(128) + ReLU + MaxPooling
    â†“
Flatten
    â†“
Dense(256) + ReLU + Dropout(0.5)
    â†“
Dense(num_classes) + Softmax
```

### ParamÃ¨tres d'entraÃ®nement

- **Optimiseur** : Adam
- **Fonction de perte** : Categorical Crossentropy
- **MÃ©triques** : Accuracy
- **Augmentation** : Rotation, Zoom, Flip horizontal

## ğŸ”§ Configuration

### Variables d'environnement (.env)

```env
DATABASE_URL=postgresql://user:password@localhost:5432/emotion_detection
MODEL_PATH=models/emotion_model.h5
CASCADE_PATH=haarcascade_frontalface_default.xml
```

## ğŸ“ˆ Performances

- **Accuracy** : ~85-90% sur le dataset de validation
- **Temps de prÃ©diction** : <100ms par image
- **DÃ©tection de visages** : Fonctionne sur des visages frontaux bien Ã©clairÃ©s

## ğŸš§ Limitations et AmÃ©liorations Futures

### Limitations actuelles
- DÃ©tection limitÃ©e aux visages frontaux
- Performance variable selon l'Ã©clairage
- Dataset limitÃ© Ã  certaines Ã©motions de base

### AmÃ©liorations prÃ©vues
- [ ] Utilisation de modÃ¨les de dÃ©tection plus robustes (MTCNN, RetinaFace)
- [ ] Fine-tuning avec des modÃ¨les prÃ©-entraÃ®nÃ©s (VGG, ResNet)
- [ ] Support de plusieurs visages dans une image
- [ ] Ajout d'une interface web
- [ ] SystÃ¨me d'authentification
- [ ] Export des donnÃ©es en CSV/Excel
- [ ] Monitoring et logging avancÃ©s

## ğŸ‘¥ Contributeurs

- **Votre Nom** - DÃ©veloppeur IA

## ğŸ“ Licence

Ce projet est sous licence MIT.

## ğŸ“ Contact

Pour toute question ou suggestion :
- Email: votre.email@example.com
- GitHub: [@votre-username](https://github.com/votre-username)

## ğŸ™ Remerciements

- OpenCV pour les outils de vision par ordinateur
- TensorFlow/Keras pour le framework de deep learning
- FastAPI pour le framework web moderne et performant
- La communautÃ© open-source pour les datasets d'Ã©motions

---

**Note** : Ce projet est un prototype dÃ©veloppÃ© Ã  des fins Ã©ducatives et de validation de concept. Pour une utilisation en production, des amÃ©liorations de sÃ©curitÃ©, de performance et de robustesse sont nÃ©cessaires.